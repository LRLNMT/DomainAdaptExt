Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/preprocess/new_bible_g1', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=222, source_lang='en_XX', srcdict='../mbart50.pretrained/dict.en_XX.txt', suppress_crashes=False, target_lang='gu_IN', task='translation', tensorboard_logdir=None, testpref='multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm', tgtdict='../mbart50.pretrained/dict.gu_IN.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=70)
[en_XX] Dictionary: 250001 types
[en_XX] multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm.en_XX: 1000 sents, 35366 tokens, 0.0% replaced (by <unk>)
[gu_IN] Dictionary: 250001 types
[gu_IN] multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm.gu_IN: 1000 sents, 42465 tokens, 0.0% replaced (by <unk>)
Wrote preprocessed data to multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/preprocess/new_bible_g1
Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/preprocess/new_bible_g1', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=222, source_lang='en_XX', srcdict='../mbart50.pretrained/dict.en_XX.txt', suppress_crashes=False, target_lang='hi_IN', task='translation', tensorboard_logdir=None, testpref='multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm', tgtdict='../mbart50.pretrained/dict.hi_IN.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=70)
[en_XX] Dictionary: 250001 types
[en_XX] multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm.en_XX: 1000 sents, 35366 tokens, 0.0% replaced (by <unk>)
[hi_IN] Dictionary: 250001 types
[hi_IN] multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm.hi_IN: 1000 sents, 40484 tokens, 0.0% replaced (by <unk>)
Wrote preprocessed data to multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/preprocess/new_bible_g1
Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/preprocess/new_bible_g1', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=222, source_lang='en_XX', srcdict='../mbart50.pretrained/dict.en_XX.txt', suppress_crashes=False, target_lang='te_IN', task='translation', tensorboard_logdir=None, testpref='multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm', tgtdict='../mbart50.pretrained/dict.te_IN.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=70)
[en_XX] Dictionary: 250001 types
[en_XX] multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm.en_XX: 1000 sents, 35366 tokens, 0.0% replaced (by <unk>)
[te_IN] Dictionary: 250001 types
[te_IN] multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/encode/new_bible_g1/test.spm.te_IN: 1000 sents, 42430 tokens, 0.0% replaced (by <unk>)
Wrote preprocessed data to multi-stage1-new_bible_g1-10k_en_XX-gu_IN_en_XX-hi_IN_en_XX-te_IN/test/preprocess/new_bible_g1
